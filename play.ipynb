{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hf = GPT2LMHeadModel.from_pretrained(\"gpt2\") # 124M parameters. model_hf is a PyTorch model. It is a subclass of torch.nn.Module.\n",
    "sd_hf = model_hf.state_dict() # the state dict of the model is the raw tensor weights of the model. \n",
    "\n",
    "for k, v in sd_hf.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_hf[\"transformer.wpe.weight\"].view(-1)[:20] # view(-1) reshapes the tensor to a 1D tensor. This is the first 20 elements of the positional embeddings. That means that the model has a maximum of 1024 tokens in a sequence and the positional embeddings are 1024-dimensional.\n",
    "# andrew talks about the flattening using view(-1), what that means is that the tensor is reshaped to a 1D tensor. The first 20 elements of the tensor are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(sd_hf[\"transformer.wpe.weight\"], cmap=\"gray\")\n",
    "\n",
    "# this is the positional embeddings of the model. The x-axis is the position of the token in the sequence and the y-axis is the dimension of the embedding. The embedding is 1024-dimensional. The model has a maximum of 1024 tokens in a sequence. The positional embeddings are learned during training.The x axis is 768-dimentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 150]) # this is the 150th dimension of the positional embeddings. The x-axis is the position of the token in the sequence. The y-axis is the value of the 150th dimension of the positional embeddings. The positional embeddings are learned during training. The x-axis is 768-dimensional.\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 200]) # this is the 200th dimension of the positional embeddings. The x-axis is the position of the token in the sequence. The y-axis is the value of the 200th dimension of the positional embeddings. The positional embeddings are learned during training. The x-axis is 768-dimensional.\n",
    "plt.plot(sd_hf[\"transformer.wpe.weight\"][:, 250]) # this is the 250th dimension of the positional embeddings. The x-axis is the position of the token in the sequence. The y-axis is the value of the 250th dimension of the positional embeddings. The positional embeddings are learned during training. The x-axis is 768-dimensional.\n",
    "\n",
    "# the positional embeddings are learned during training. The x-axis is 768-dimensional. The y-axis is the value of the positional embeddings. The positional embeddings are 1024-dimensional. The model has a maximum of 1024 tokens in a sequence. The positional embeddings are learned during training. The x-axis is 768-dimensional.\n",
    "# the jaggedness of the plot is due to the fact that the positional embeddings are learned during training.  After the training, the curve will be smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sd_hf[\"transformer.h.1.attn.c_attn.weight\"][:300,:300], cmap=\"gray\")\n",
    "\n",
    "# The provided code is using the imshow() function from the matplotlib.pyplot module to display an image.\n",
    "\n",
    "# The imshow() function takes several parameters to customize the image display. Let's go through some of the important parameters used in the code:\n",
    "\n",
    "# X: This parameter represents the image data that will be displayed. It can be either an array-like object or a PIL.Image.Image object. In this case, it seems to be accessing a specific portion of an array called sd_hf[\"transformer.h.1.attn.c_attn.weight\"] using slicing ([:300,:300]), which selects the first 300 rows and columns of the array.\n",
    "\n",
    "# cmap: This parameter specifies the colormap to be used for mapping the image data values to colors. In the code, it is set to \"gray\", indicating that a grayscale colormap will be used.\n",
    "\n",
    "# The imshow() function returns an AxesImage object, which represents the image displayed on the plot. In this code snippet, the return value is not stored in a variable, so it is not being used further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(30) #originally was 42, we changed it to 30 because its relevance in dark souls for mid stats 30 is the soft cap for most stats. 42 is the answer to the ultimate question of life, the universe, and everything.\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n",
    "\n",
    "# The provided code is using the Hugging Face library called \"transformers\" to generate text using a pre-trained language model called GPT-2.\n",
    "\n",
    "# First, the code imports the necessary modules from the \"transformers\" library. The pipeline function is imported to create a text generation pipeline, and the set_seed function is imported to set a seed value for reproducibility.\n",
    "\n",
    "# Next, the code creates an instance of the text generation pipeline by calling the pipeline function with the argument 'text-generation'. This tells the pipeline that we want to generate text. The model parameter is set to 'gpt2', which specifies that we want to use the GPT-2 model for text generation.\n",
    "\n",
    "# After that, the set_seed function is called with the argument 42. This sets the seed value for random number generation, which ensures that the generated text will be the same each time the code is run with the same seed value. This is useful for reproducibility. 42 is not a special number but is commonly used as a seed value in examples.\n",
    "\n",
    "# Finally, the code generates text by calling the generator function with the input prompt \"Hello, I'm a language model,\" and additional parameters max_length=30 and num_return_sequences=5. This specifies that we want to generate text with a maximum length of 30 tokens and return 5 different sequences of generated text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
